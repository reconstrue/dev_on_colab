{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CeC-AbggYh6s"
   },
   "source": [
    "# Colab VM configuration information\n",
    "\n",
    "This notebook is intended simply for dumping status information from a Colab runtime (kernel, VM, whatever)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3SbviHli8Er"
   },
   "outputs": [],
   "source": [
    "# Various installs of packages imported by colab_vm_config_info.ipynb\n",
    "!pip install humanize\n",
    "!pip install gputil\n",
    "!pip install psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qv-SjRT3KsUT"
   },
   "source": [
    "## Python environment stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dhQ_f7n1K_eK",
    "outputId": "608c5215-7c74-41e4-8b11-3127142108a0"
   },
   "outputs": [],
   "source": [
    "# What version of Python is in effect?\n",
    "\n",
    "import platform\n",
    "\n",
    "a_message = \"Python runtime version: \" + platform.python_version() \n",
    "print(a_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EV6LDzpn0BgX"
   },
   "outputs": [],
   "source": [
    "# What packages are installed for the detected running version of Python?\n",
    "import platform\n",
    "\n",
    "python_major_version = int(platform.python_version_tuple()[0])\n",
    "print(python_major_version)\n",
    "\n",
    "if python_major_version == 3:\n",
    "  print(\"Python 3.6 dist-packages\")\n",
    "  !ls /usr/local/lib/python3.6/dist-packages\n",
    "else: \n",
    "  # Python 2 it is...\n",
    "  print(\"Python 2.7 dist-packages\")\n",
    "  !ls /usr/local/lib/python2.7/dist-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IMWkr5BRhJwi"
   },
   "source": [
    "## Jupyter stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "3_XbzwHbhOCs",
    "outputId": "c00008ce-3ab7-428e-968f-cf6b9e05df9b"
   },
   "outputs": [],
   "source": [
    "!jupyter-kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uxbfElYWtEGX"
   },
   "source": [
    "## Check VM Uptime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUVolHFGAELj"
   },
   "source": [
    "Supposedly these Colab kernel (runtimes, VMs, whatever) are thrown away after a max of 12 hours. In the results of `uptime` is the time-of-day (formatted `HH:MM:SS`) followed by ` up: ` followed by how long the VM has been up (formatted as `XX min`, or after an hour as `H:MM`).\n",
    "\n",
    "Note, the 12 hour lifetime cap is the max but less can happen it seems. Seemingly, [this issue is not well defined by google](https://stackoverflow.com/questions/55050988/can-i-run-a-google-colab-free-edition-script-and-then-shutdown-my-computer).\n",
    "\n",
    "Furthermore, VM max lifetime is different than the constant runtime disconnects. These seem to happen on the order of 60 to 90 minutes. Supposedly keeping a code cell running can keep the connection from disconnect timeouts. Note though that editing text cells does not reset the timeout clock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hw4ETaUArMJK",
    "outputId": "ff66a2f4-3e1f-4de2-b736-492b822c9462"
   },
   "outputs": [],
   "source": [
    "# How long has this VM been up? \n",
    "!uptime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xey9UaJVCyqR"
   },
   "source": [
    "## Reset VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DvI-zBE8dwud"
   },
   "outputs": [],
   "source": [
    "# Reset VM\n",
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_rim_Xy3h--W"
   },
   "source": [
    "## CPU Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Cd9OM-gSYdaE",
    "outputId": "d1b766bb-954f-4ef6-aa93-3cdc6f07b60f"
   },
   "outputs": [],
   "source": [
    "# How many CPUs does this machine have?\n",
    "!lscpu | grep \"^CPU(s):\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 944
    },
    "colab_type": "code",
    "id": "z7eY-Lq9dFBy",
    "outputId": "5c994b17-b598-4d8b-a442-7b2dd642fa3d"
   },
   "outputs": [],
   "source": [
    "# More details on the CPU(s):\n",
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhb8bXJIZU9t"
   },
   "outputs": [],
   "source": [
    "# RAM\n",
    "!cat /proc/meminfo | head -n3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeSy0EpOigS_"
   },
   "outputs": [],
   "source": [
    "# RAM info humanized\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tl8OjjKSEp_4"
   },
   "source": [
    "## File System\n",
    "\n",
    "As with AWS Lambda, there are intentionally few switches for selecting VM options. Memory and CPU are provided as matching packages, not independently configurable.\n",
    "\n",
    "So, depending on what you ask for in terms of compute (CPU, GPU, [TPU](https://colab.research.google.com/notebooks/tpu.ipynb)) you get more or less file system memory [[*](https://stackoverflow.com/a/55890688)]. Note: for all compute options, the OS files initialize to consuming about 25MB of the file system before you are dropped into the kernel. \n",
    "\n",
    "On 2019-05-19, the following tests gave these results:\n",
    "\n",
    "Processor | FS Free GB | FS Total GB \n",
    "--|--|--\n",
    "CPU | 24 | 49\n",
    "GPU | 318 | 359\n",
    "TPU | 26| 49\n",
    "\n",
    "The low FS size for the TPU is probably because for the TPU case, those (the actually TPU boards) are separate machines while for GPUs those  are a part of the machine the notebook is running on. So, for the CPU and the TPU options, Google is probably providing the same VM, ergo the file systems are essentially the same size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "XITlujDERuVd",
    "outputId": "0d595737-505a-4d7c-abe8-6ce3d9b20058"
   },
   "outputs": [],
   "source": [
    "!df -h ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HeD7R1g_iFLO"
   },
   "source": [
    "## GPU Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "a-tpXTLhbsg7",
    "outputId": "4982928b-5bf4-49c8-e4fa-8f0c9eda2544"
   },
   "outputs": [],
   "source": [
    "# What GPU is currently config'd for use?\n",
    "\n",
    "# https://colab.research.google.com/notebooks/gpu.ipynb\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\"GPU detected: NONE\")\n",
    "else:\n",
    "  print('GPU detected: {}'.format(device_name))\n",
    "\n",
    "# TODO: Another way?\n",
    "#from tensorflow.python.client import device_lib\n",
    "#device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SnpoONR1hBEC"
   },
   "outputs": [],
   "source": [
    "# Memory in GPU\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "\n",
    "import GPUtil as GPU\n",
    "\n",
    "gpus = GPU.getGPUs()\n",
    "\n",
    "if len(gpus) > 0:\n",
    "  gpu = gpus[0]\n",
    "  print(\"GPU RAM:\\n Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "else:\n",
    "  print(\"GPU detected: NONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "Yc4jEhFyZDRi",
    "outputId": "17b8bdfe-fc59-409d-ebd4-5095eed316c5"
   },
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "!conda install tsnecuda cuda100 -c cannylab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5t8eFMPaJdc"
   },
   "source": [
    "## References\n",
    "\n",
    "* [Google Colab Free GPU Tutorial](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)\n",
    "* [GPU stats code](https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available)\n",
    "* [TensorFlow with GPU](https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=3IEVK-KFxi5Z)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab_vm_config_info.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
