{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_vm_config.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CeC-AbggYh6s"
      },
      "source": [
        "# Colab VM configuration\n",
        "\n",
        "This notebook is intended simply for dumping status information from a Colab runtime (read: kernel).\n",
        "\n",
        "## Setup system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m3SbviHli8Er",
        "colab": {}
      },
      "source": [
        "# Various installs of packages imported by colab_vm_config_info.ipynb\n",
        "!pip install humanize\n",
        "!pip install gputil\n",
        "!pip install psutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1NI-ediP0Uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import humanize\n",
        "import platform\n",
        "import psutil\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W69UZ_QfAjf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Request TF 2.x, not 1.x\n",
        "try:\n",
        "  # %tensorflow_version is a Colab-only thing \n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  print(\"TensorFlow 2.x does not seem to be available\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qv-SjRT3KsUT"
      },
      "source": [
        "## Python environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dhQ_f7n1K_eK",
        "colab": {}
      },
      "source": [
        "# What version of Python is in effect?\n",
        "a_message = \"Python runtime version: \" + platform.python_version() \n",
        "print(a_message)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EV6LDzpn0BgX",
        "colab": {}
      },
      "source": [
        "# What packages are installed for the detected running version of Python?\n",
        "python_major_version = int(platform.python_version_tuple()[0])\n",
        "print(python_major_version)\n",
        "\n",
        "if python_major_version == 3:\n",
        "  print(\"Python 3.6 dist-packages\")\n",
        "  !ls /usr/local/lib/python3.6/dist-packages\n",
        "else: \n",
        "  # Python 2 it is...\n",
        "  print(\"Python 2.7 dist-packages\")\n",
        "  !ls /usr/local/lib/python2.7/dist-packages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IMWkr5BRhJwi"
      },
      "source": [
        "## Jupyter\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3_XbzwHbhOCs",
        "colab": {}
      },
      "source": [
        "!jupyter-kernelspec list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_rim_Xy3h--W"
      },
      "source": [
        "## CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cd9OM-gSYdaE",
        "colab": {}
      },
      "source": [
        "# How many CPUs does this machine have?\n",
        "!lscpu | grep \"^CPU(s):\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z7eY-Lq9dFBy",
        "colab": {}
      },
      "source": [
        "# More details on the CPU(s):\n",
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uhb8bXJIZU9t",
        "colab": {}
      },
      "source": [
        "# RAM\n",
        "!cat /proc/meminfo | head -n3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LeSy0EpOigS_",
        "colab": {}
      },
      "source": [
        "# RAM info humanized\n",
        "process = psutil.Process(os.getpid())\n",
        "print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tl8OjjKSEp_4"
      },
      "source": [
        "## File system\n",
        "\n",
        "As with AWS Lambda, there are intentionally few switches for selecting VM options. Memory and CPU are provided as matching packages, not independently configurable.\n",
        "\n",
        "So, depending on what you ask for in terms of compute (CPU, GPU, [TPU](https://colab.research.google.com/notebooks/tpu.ipynb)) you get more or less file system memory [[*](https://stackoverflow.com/a/55890688)]. Note: for all compute options, the OS files initialize to consuming about 25MB of the file system before you are dropped into the kernel. \n",
        "\n",
        "On 2019-05-19, the following tests gave these results:\n",
        "\n",
        "Processor | FS Free GB | FS Total GB \n",
        "--|--|--\n",
        "CPU | 24 | 49\n",
        "GPU | 318 | 359\n",
        "TPU | 26| 49\n",
        "\n",
        "The low FS size for the TPU is probably because for the TPU case, those (the actually TPU boards) are separate machines while for GPUs those  are a part of the machine the notebook is running on. So, for the CPU and the TPU options, Google is probably providing the same VM, ergo the file systems are essentially the same size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XITlujDERuVd",
        "colab": {}
      },
      "source": [
        "!df -h ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HeD7R1g_iFLO"
      },
      "source": [
        "## GPU information\n",
        "\n",
        "First, is a GPU allocated for this notebook's VM to work with?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a-tpXTLhbsg7",
        "colab": {}
      },
      "source": [
        "# What GPU is currently config'd for use?\n",
        "\n",
        "# https://colab.research.google.com/notebooks/gpu.ipynb\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\"GPU detected: NONE\")\n",
        "else:\n",
        "  print('GPU detected: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTUBie3AB5rV",
        "colab_type": "text"
      },
      "source": [
        "Assuming we have a GPU, what kind? The answer is in the final line of the following cell's output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nFVApqaBqcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SnpoONR1hBEC",
        "colab": {}
      },
      "source": [
        "# Memory in GPU\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "\n",
        "import GPUtil as GPU\n",
        "\n",
        "gpus = GPU.getGPUs()\n",
        "\n",
        "if len(gpus) > 0:\n",
        "  gpu = gpus[0]\n",
        "  print(\"GPU RAM:\\n Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "else:\n",
        "  print(\"GPU detected: NONE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yc4jEhFyZDRi",
        "colab": {}
      },
      "source": [
        "!nvcc --version\n",
        "!conda install tsnecuda cuda100 -c cannylab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m5t8eFMPaJdc"
      },
      "source": [
        "## References\n",
        "\n",
        "* [Google Colab Free GPU Tutorial](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)\n",
        "* [GPU stats code](https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available)\n",
        "* [TensorFlow with GPU](https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=3IEVK-KFxi5Z)"
      ]
    }
  ]
}